{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish Analytic Notebook\n",
    "The following notebook runs through the process of creating and training a dataset for a site-specific model\n",
    "\n",
    "## Workflow\n",
    "- FFMPEG extracts frames from video and saves to a folder\n",
    "- Florence-2 locates fish in the images and creates a set of bounding boxes\n",
    "- Bounding boxes are used to assist SAM-2 in creating segmentation masks\n",
    "- Segmentation masks are converted to COCO format polygons and exported as a .JSON file\n",
    "- - optional step\n",
    "  - import images and .JSON file into CVAT to add species labels to annotations\n",
    "  - export as COCO JSON file\n",
    "- Convert JSON file to YOLO bounding box format\n",
    "- Detect small annotations (as <1% of frame) and assign them to the discard class\n",
    "- Detect overlapping boxes and assign them to the discard class\n",
    "- - must do if optional step wasn't done above\n",
    "  - import images and YOLO files into CVAT to add species labels to annotations\n",
    "- Explode out remaining images and store as seperate images files with new YOLO annotations\n",
    "- Select images for training/validation/testing\n",
    "- Initiate YOLO training from created dataset.\n",
    "- Run inference using model trained from previous step\n",
    "- Extract MaxN and create species accumulation data\n",
    "- Some magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fm0XP28Y1BT",
    "outputId": "be02c69b-0594-4c0f-f3f9-604cb8500544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 08:53:58 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P8              9W /   75W |       0MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     11320      C   ...rograms\\Python\\Python312\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup working directories\n",
    "This notebook should be started from a root folder where the following two folders are subdirectories of. It could probably work, but I haven't tested it.\n",
    "- AIDIR - used to define where the AI scripts reside (YOLO, SAM-2 & FLORENCE-2)\n",
    "- ANNODIR - used to define where the annotation files and images reside. In my setup, they are all setup in further subdirectories based on site and annotation method. Also contains post-processing scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DIR: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORKING_DIR = os.getcwd()\n",
    "AIDIR = 'C:\\\\Users\\\\neez\\\\OneDrive\\\\Uni\\\\VLS301\\\\detect_scripts'\n",
    "ANNODIR = 'C:\\\\Users\\\\neez\\\\OneDrive\\\\Uni\\\\VLS301\\\\Completed_Annotations'\n",
    "print(\"WORKING_DIR:\", WORKING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract video frames\n",
    "\n",
    "Variables to extract frames from initial video\n",
    "* INITVID_SOURCE_LOCATION = Location of video file to train from\n",
    "* INITVID_EXTRACT_LOCATION_ANNO = Location to store image files from video to use in annotation\n",
    "* INITVID_EXTRACT_LOCATION_DETECT = Location to store image files from video to use in annotation\n",
    "* INITVID_START_TIME = Time in the video to start extracting frames from (hh:mm:ss)\n",
    "* INITVID_EXTRACT_LENGTH = Length of time in the video to extract (from start time) (hh:mm:ss)\n",
    "* INITVID_EXTRACT_FPS = Frames per Second to extract for annotation dataset (5 = 5fps, 1/30 = 1fp30s)\n",
    "\n",
    "YOLO parameters\n",
    "* YOLO_TRN_EPOCHS = Yolo training epochs (100 is a good place to start)\n",
    "* YOLO_TRN_BATCH_SIZE = Yolo training bacth size (16 is what I generally use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"Waychinicup_1fp15s\"\n",
    "\n",
    "INITVID_SOURCE_LOCATION = \"C:\\\\Users\\\\neez\\\\OneDrive\\\\Uni\\\\VLS301\\\\Waychinicup_full.mp4\"\n",
    "INITVID_EXTRACT_LOCATION_ANNO = os.path.join(WORKING_DIR, PROJECT_NAME, \"Annotate\")\n",
    "INITVID_EXTRACT_LOCATION_DETECT = os.path.join(WORKING_DIR, PROJECT_NAME, \"Detect\")\n",
    "INITVID_START_TIME = \"0:02:09\" # Time BRUV has steadied on substrate\n",
    "INITVID_EXTRACT_LENGTH = \"1:00:00\" # 1 hour of footage\n",
    "INITVID_EXTRACT_FPS = \"1/15\"\n",
    "\n",
    "YOLO_TRN_EPOCHS = 100\n",
    "YOLO_TRN_BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts files for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(INITVID_EXTRACT_LOCATION_ANNO, exist_ok=True)\n",
    "\n",
    "# Build ffmpeg command\n",
    "ffmpeg_cmd = f'ffmpeg -i \"{INITVID_SOURCE_LOCATION}\" ' \\\n",
    "            f'-ss {INITVID_START_TIME} ' \\\n",
    "            f'-t {INITVID_EXTRACT_LENGTH} ' \\\n",
    "            f'-vf \"fps={INITVID_EXTRACT_FPS}\" ' \\\n",
    "            f'-q:v 2 \"{INITVID_EXTRACT_LOCATION_ANNO}/frame_%04d.jpg\"'\n",
    "\n",
    "# Execute ffmpeg command\n",
    "print(\"Extracting files for automated annotation:\")\n",
    "print(ffmpeg_cmd)\n",
    "!{ffmpeg_cmd}\n",
    "\n",
    "# Verify output\n",
    "extracted_frames = list(Path(INITVID_EXTRACT_LOCATION).glob('*.jpg'))\n",
    "print(f\"\\nExtracted {len(extracted_frames)} frames to {INITVID_EXTRACT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts files for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(INITVID_EXTRACT_LOCATION_DETECT, exist_ok=True)\n",
    "\n",
    "# Build ffmpeg command\n",
    "ffmpeg_cmd = f'ffmpeg -i \"{INITVID_SOURCE_LOCATION}\" ' \\\n",
    "            f'-ss {INITVID_START_TIME} ' \\\n",
    "            f'-t {INITVID_EXTRACT_LENGTH} ' \\\n",
    "            f'-vf \"fps=2\" ' \\\n",
    "            f'-q:v 2 \"{INITVID_EXTRACT_LOCATION_DETECT}/frame_%04d.jpg\"'\n",
    "\n",
    "# Execute ffmpeg command\n",
    "print(\"Extracting files for automated annotation:\")\n",
    "print(ffmpeg_cmd)\n",
    "!{ffmpeg_cmd}\n",
    "\n",
    "# Verify output\n",
    "extracted_frames = list(Path(INITVID_EXTRACT_LOCATION).glob('*.jpg'))\n",
    "print(f\"\\nExtracted {len(extracted_frames)} frames to {INITVID_EXTRACT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and setup SAM-2\n",
    "These only need to be run once when setting up the system. Does not need to be run everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(AIDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGwU0R7Da1VD",
    "outputId": "fd9b1958-8d47-473f-e173-59100d1861d4"
   },
   "outputs": [],
   "source": [
    "!pip install flash_attn -q timm -q\n",
    "!pip install accelerate -q\n",
    "!pip install einops -q\n",
    "!pip install -q supervision\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGwU0R7Da1VD",
    "outputId": "fd9b1958-8d47-473f-e173-59100d1861d4"
   },
   "outputs": [],
   "source": [
    "!mkdir my_models\n",
    "!mkdir my_models/Florence_2\n",
    "\n",
    "!curl -o {AIDIR}\\my_models\\sam2\\sam2_hiera_tiny.pt https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\n",
    "!curl -o {AIDIR}\\my_models\\sam2\\sam2_hiera_small.pt https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt\n",
    "!curl -o {AIDIR}\\my_models\\sam2\\sam2_hiera_base_plus.pt https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\n",
    "!curl -o {AIDIR}\\my_models\\sam2\\sam2_hiera_large.pt https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EaP8mqfZltu",
    "outputId": "58bb7405-9f32-4aa5-9dbb-396876dd91d8"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/segment-anything-2.git\n",
    "%cd segment-anything-2\n",
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and setup YOLO\n",
    "These only need to be run once when setting up the system. Does not need to be run everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.5 torch-2.5.0+cpu CPU (12th Gen Intel Core(TM) i7-1280P)\n",
      "Setup complete  (20 CPUs, 15.7 GB RAM, 426.6/930.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.2.103 -q\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Florence-2 discovery\n",
    "This does need to be run as this loads in the Florence-2 modules to perform the initial inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRDIR: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\detect_scripts\n"
     ]
    }
   ],
   "source": [
    "os.chdir(AIDIR)\n",
    "CURRDIR = os.getcwd()\n",
    "print(\"CURRDIR:\", CURRDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617,
     "referenced_widgets": [
      "57d36825e7124ebe961876d1693b576a",
      "7eb97169f1d142f0b78823a436933d20",
      "b1d352743b1c434f8313702135584076",
      "fa631ad069154a899fa46c02a0d3a8c4",
      "2920875af6a5405eb5345db9e3585a2b",
      "71a62d265204456ebbce0bac2d7cbf8b",
      "a27ecd3682c6474db9b94426bcf2a0f4",
      "2e89bd0094bc4eeeb2c4aa077a32c7e2",
      "f80e27fc19864adc9eccaeb8fb947138",
      "b6f69234b4974985a30dc9a40e686eb5",
      "f4344dec7b914275b53db4d4362ba01a",
      "5bddf4d19635405d962597d13008d73c",
      "ad9cad15cfcc44af87bea293836573ad",
      "270b2ddf3a834008be92b6f8c6538f57",
      "8ae3c9792abc450081d38953603c8deb",
      "f88034dc172a47e0b980cad80c657bb3",
      "fdcc974c39bb4eef807565b213b24549",
      "3954fa1c2ad448e7934111d8f698c521",
      "448e93a9a1f6473994cafcf90e026320",
      "9c48b2b947d34ef498dc4404359a0556",
      "257c4273556e426c846042927d24953c",
      "6184c726f8c846328125098b30a75d67",
      "f0b6122c13cc4eea97aa7dc6ab13a3c8",
      "f074a90818ab42a7885ee407cf5ffa7f",
      "394a13b7f49f4d70b7ebd7ea6f5924ac",
      "077a1fcc8a14437c96b9b61bea0e02b3",
      "629fd09a98b546adb8ffc4a66a9664ea",
      "7d2af33b8e0c4198aef64a56b20ca1eb",
      "20e838e97d564e7583db5a606b43fb2c",
      "0e717f61ffc94c99bf7ea9afd588a7ac",
      "a1cae4b0a04f4344ae8e50ef9a5db948",
      "c84ab06afe1948a9be90109f20c8d3aa",
      "88ed1766b43f4c3abeabb6a7432b2512",
      "9f5ceeccc60b43a3bdd74335b5bea26e",
      "ef42b603953647af94ef83a0e992a1b0",
      "376fe8e540ae43ad807df362de36dc9c",
      "3fa78570b3db434b9aeb37d3baf200af",
      "a987f90ef00344119b5f98601a26cb6e",
      "c2f29d93b50344d18632ee35a90b3013",
      "747024b3473d465b85109294fd926238",
      "47cd8c0bd53f4d8cb309637242333c00",
      "c030d8a53dcb443a9d0aa5d98e543632",
      "4e91cf2a01c64e2086ad7c8dc859955e",
      "535295b7f27c4b57885f33a06636a009",
      "282998972a5747b8bbd2484ad2351e23",
      "27a07653034f41d5a0ffac79c70b7ecf",
      "0310dd136fa54b06886b254c2f3ef0cb",
      "29a70a9ed82f4ae5a0dc6c5f356c6841",
      "fc5fe0bea7e94e38ab66bbe43edc28b6",
      "559e902f6e3b4e47bbdf631f8a35d62b",
      "5b2aee580af749988850fe07216a9b50",
      "b7c27309edad468d946975b620e0b659",
      "8d80378f864444af945fc3599c3f65b1",
      "eaafcb3b2cbc42d3bf81539f9a42ead9",
      "145f810b2fbf4ddeb01054e281a1e4f9",
      "4510d1cab9be4398a5f68df83ca7065e",
      "4bb1b68ab33e47789f854e9dcc4e65ee",
      "0f051e89ae8e452ab40414a7c9381e12",
      "246a0e46d36d4d1182621bc58128faa4",
      "81f9a42c24cb4d94b45137debad99f42",
      "7ac408daa5b74b0f8fe5a9f299d24188",
      "c44a7838338341a3a845680d2ab1341a",
      "0411989350ff48248062361fc129433a",
      "b8250a63ed0745b7bf4800dcc64853db",
      "873692b38c4b472da0c017fe58c66b1a",
      "b3a35db5b4954c6fbfccef0ad3f80659",
      "6abbd8c3305749b6a70ca2667e7c12fd",
      "bda44ac5376a419989f2e4165588dcc8",
      "4778076a30cb4772be7a1cedd5341020",
      "7827386dffab4c2fb5ba977e7f34bdde",
      "1500161f52c04cc9a758d34c3e1148d4",
      "537bc6c96deb4ab1bf0c8e6c4b1451ab",
      "f4107cdf82f446ff88ac544487aedd4e",
      "11212eab35a343e7a7e84721af597376",
      "4f302ad2b2fd43aa8158670eb4e59acc",
      "94d91a7054af4da1806d2ece8eb552cd",
      "28cfc14aca97433f882c9deb5398a03e",
      "56d6534201d640a58fd697c70b2d6d9d",
      "275a1f0fa21542b3b71c800dc60eb266",
      "08ce0d91d81c41cf95d3f0fb81352910",
      "2d4e1bfcf0b34efd866c199086942f6d",
      "3f0f0c4ebaee428e984955ce5e87a3ec",
      "b080ac78fd5d4619970ea696649ab392",
      "51ea070acb5346e7a9643e62002bc868",
      "0b8bb4acd00e40008230d5b94102d092",
      "3697e80878094c8099aecdc947a598e1",
      "1d38210d8fde4ff89f5febf86ae6f4fc",
      "a162c364c61349e4950f72e3c2bef4ff",
      "8fc68b03c5dc4ef38b94de606269a1f8",
      "56c86ad23dba49ef9527c45f6baec402",
      "7cb50a8d6c3f42769fcbd2740bcccc0d",
      "07481c2fd67e4fc2bd0adf74035a5f1c",
      "cdccc14b5a2a4e59b88c191f3f19e38e",
      "99a93569e9f044cbb2f9e8ddd6d12e06",
      "e64b1ac4a7b848ceaa4c4725afc944bf",
      "0409bace810b4653bb278dd7d8dd3597",
      "f884d62dbdd6491e95d690fc9020e491",
      "0bc18d57f0334101b7f2975f4400722c",
      "651778e0e2494e858889cd36a51ac315",
      "e654c3267ae84924912e47b8a5d3f37c",
      "38cd83e638134e69b4c1dcbdba286688",
      "8603dc2bb7794c64b66e29c9cf1ea2d9",
      "3f3730a17c9841e4b726e444f0e361a5",
      "e4a7be23d5424284ba2b8623dc38a446",
      "0d519131d12b4e07ac25885ff432ed69",
      "57e8e374a2be448d8b062f53a4d99b02",
      "90e7da0409264624b65720f3138f9130",
      "bded8c3ec2b74be4b20cbf8a46d1e97e",
      "8518e339120b4fac82ce72c4919b2fb8",
      "ca6aefb7f2fe4143a7dd2cde1a40255b"
     ]
    },
    "id": "Jea_BUr9bgUt",
    "outputId": "abc6bf7b-99dd-4ad9-93f3-32a3944b76b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neez\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "C:\\Users\\neez\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large-ft\",\n",
    "                                             cache_dir=f\"{AIDIR}/my_models/Florence_2\",\n",
    "                                             device_map=\"cuda\",\n",
    "                                             trust_remote_code=True)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large-ft\",\n",
    "                                             cache_dir=f\"{AIDIR}/my_models/Florence_2\",\n",
    "                                             trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3LvexNyGSuEN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from datetime import datetime\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fish Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_fish(image):\n",
    "    PROMPT = \"<OD>\"\n",
    "    task_type = \"<OD>\"\n",
    "\n",
    "    inputs = processor(text=PROMPT, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    text_generations = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    results = processor.post_process_generation(text_generations,\n",
    "    task=task_type, image_size=(image.width, image.height))\n",
    "\n",
    "    raw_lists = []\n",
    "\n",
    "    for bbox, label in zip(results[task_type]['bboxes'], results[task_type]['labels']):\n",
    "        if label == \"fish\":\n",
    "            raw_lists.append(bbox)\n",
    "\n",
    "    return raw_lists, results[task_type]['labels']\n",
    "\n",
    "def convert_mask_to_polygon(mask):\n",
    "    \"\"\"Convert binary mask to COCO polygon format.\"\"\"\n",
    "    print(f\"Input mask shape: {mask.shape}\")\n",
    "    print(f\"Input mask dtype: {mask.dtype}\")\n",
    "    print(f\"Input mask values range: [{mask.min()}, {mask.max()}]\")\n",
    "    \n",
    "    # Ensure mask is 2D and binary\n",
    "    if len(mask.shape) > 2:\n",
    "        mask = np.squeeze(mask)\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    try:\n",
    "        # Find contours\n",
    "        contours = measure.find_contours(binary_mask, 0.5)\n",
    "        print(f\"Found {len(contours)} contours\")\n",
    "        \n",
    "        # Convert contours to COCO format\n",
    "        polygons = []\n",
    "        for contour in contours:\n",
    "            if len(contour) < 3:\n",
    "                continue\n",
    "            polygon = []\n",
    "            for point in contour:\n",
    "                polygon.extend([float(point[1]), float(point[0])])\n",
    "            polygons.append(polygon)\n",
    "        \n",
    "        if not polygons:\n",
    "            print(\"No valid polygons found, creating bounding box\")\n",
    "            h, w = binary_mask.shape\n",
    "            box_polygon = [0, 0, w, 0, w, h, 0, h]\n",
    "            polygons.append(box_polygon)\n",
    "            \n",
    "        return polygons\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in convert_mask_to_polygon: {str(e)}\")\n",
    "        print(f\"Mask shape after processing: {binary_mask.shape}\")\n",
    "        raise\n",
    "\n",
    "def visualize_florence_and_sam2(image, boxes, masks):\n",
    "    \"\"\"Visualization function\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Plot Florence-2 detections\n",
    "    ax1.imshow(image)\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2,\n",
    "            edgecolor='red',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax1.add_patch(rect)\n",
    "    ax1.set_title(\"Florence-2 Detections\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot SAM2 segmentations\n",
    "    ax2.imshow(image)\n",
    "    colors = ['red', 'blue', 'green', 'yellow', 'purple']\n",
    "    \n",
    "    for i, mask in enumerate(masks):\n",
    "        color = colors[i % len(colors)]\n",
    "        colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        if i == 0:\n",
    "            colored_mask[mask > 0.5] = [255, 0, 0]\n",
    "        elif i == 1:\n",
    "            colored_mask[mask > 0.5] = [0, 255, 0]\n",
    "        else:\n",
    "            colored_mask[mask > 0.5] = [0, 0, 255]\n",
    "            \n",
    "        ax2.imshow(colored_mask, alpha=0.3)\n",
    "        \n",
    "        box = boxes[i]\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2,\n",
    "            edgecolor=color,\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax2.add_patch(rect)\n",
    "    ax2.set_title(\"SAM2 Segmentations\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def process_directory_to_coco(input_dir, output_json, visualize=False):\n",
    "    \"\"\"\n",
    "    Process all images in a directory and create COCO format annotations.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing images\n",
    "        output_json: Path to save the COCO json file\n",
    "        visualize: Whether to show visualizations for each image\n",
    "    \"\"\"\n",
    "    # Initialize COCO dataset structure\n",
    "    coco_dataset = {\n",
    "        \"info\": {\n",
    "            \"year\": datetime.now().year,\n",
    "            \"version\": \"1.0\",\n",
    "            \"description\": \"Fish Dataset\",\n",
    "            \"contributor\": \"Your Name\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"fish\",\n",
    "                \"supercategory\": \"animal\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    # Get list of images\n",
    "    image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.jpg\")))\n",
    "    print(f\"Found {len(image_paths)} images to process\")\n",
    "\n",
    "    # Setup SAM2 model (do this once outside the loop)\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    CHECKPOINT = f\"{AIDIR}/my_models/sam2/sam2_hiera_small.pt\"\n",
    "    CONFIG = f\"{AIDIR}/segment-anything-2/sam2/configs/sam2/sam2_hiera_s.yaml\"\n",
    "    sam2_model = build_sam2(CONFIG, CHECKPOINT, device=DEVICE, apply_postprocessing=False)\n",
    "    \n",
    "    annotation_id = 1  # Counter for annotation IDs\n",
    "\n",
    "    # Process each image\n",
    "    for image_id, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nProcessing image {image_id + 1}/{len(image_paths)}: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            \n",
    "            # Add image info to COCO dataset\n",
    "            image_info = {\n",
    "                \"id\": image_id,\n",
    "                \"file_name\": os.path.basename(image_path),\n",
    "                \"width\": image.width,\n",
    "                \"height\": image.height,\n",
    "                \"date_captured\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            coco_dataset[\"images\"].append(image_info)\n",
    "\n",
    "            # Get Florence-2 detections\n",
    "            boxes, labels = find_all_fish(image)\n",
    "            print(f\"Florence-2 detection results - Boxes: {len(boxes)}, Labels: {len(labels)}\")\n",
    "\n",
    "            if len(boxes) > 0:\n",
    "                # Setup SAM2 predictor for this image\n",
    "                predictor = SAM2ImagePredictor(sam2_model)\n",
    "                predictor.set_image(image)\n",
    "\n",
    "                # Get SAM2 masks\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    box=boxes,\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                print(f\"SAM2 prediction results - Masks shape: {masks.shape}\")\n",
    "\n",
    "                # Ensure masks is 3D (N, H, W)\n",
    "                if len(masks.shape) == 2:\n",
    "                    masks = masks[np.newaxis, :, :]\n",
    "                elif len(masks.shape) == 4:\n",
    "                    masks = np.squeeze(masks, axis=1)\n",
    "\n",
    "                # Create COCO annotations\n",
    "                for i, (mask, box) in enumerate(zip(masks, boxes)):\n",
    "                    try:\n",
    "                        # Ensure mask is 2D binary\n",
    "                        binary_mask = mask.astype(np.uint8)\n",
    "                        \n",
    "                        # Find contours using cv2 instead of skimage\n",
    "                        contours, _ = cv2.findContours(\n",
    "                            binary_mask, \n",
    "                            cv2.RETR_EXTERNAL, \n",
    "                            cv2.CHAIN_APPROX_SIMPLE\n",
    "                        )\n",
    "                        \n",
    "                        # Convert contours to COCO polygon format\n",
    "                        polygons = []\n",
    "                        for contour in contours:\n",
    "                            # Flatten the contour and convert to list\n",
    "                            contour = contour.flatten().tolist()\n",
    "                            # Convert to x,y pairs\n",
    "                            polygon = []\n",
    "                            for j in range(0, len(contour), 2):\n",
    "                                polygon.extend([float(contour[j]), float(contour[j+1])])\n",
    "                            if len(polygon) >= 6:  # Must have at least 3 points\n",
    "                                polygons.append(polygon)\n",
    "                        \n",
    "                        # If no valid polygons found, use bounding box\n",
    "                        if not polygons:\n",
    "                            x1, y1, x2, y2 = map(float, box)\n",
    "                            polygons = [[x1, y1, x2, y1, x2, y2, x1, y2]]\n",
    "                        \n",
    "                        # Calculate area\n",
    "                        area = float(binary_mask.sum())\n",
    "                        \n",
    "                        # Create annotation\n",
    "                        annotation = {\n",
    "                            \"id\": annotation_id,\n",
    "                            \"image_id\": image_id,\n",
    "                            \"category_id\": 1,  # fish\n",
    "                            \"segmentation\": polygons,\n",
    "                            \"area\": area,\n",
    "                            \"bbox\": [float(box[0]), float(box[1]), \n",
    "                                   float(box[2] - box[0]), float(box[3] - box[1])],\n",
    "                            \"iscrowd\": 0\n",
    "                        }\n",
    "                        \n",
    "                        coco_dataset[\"annotations\"].append(annotation)\n",
    "                        annotation_id += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing mask {i} for image {image_path}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "            if visualize:\n",
    "                # Create visualization\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "                \n",
    "                # Show original image with boxes\n",
    "                ax1.imshow(image)\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                          linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax1.add_patch(rect)\n",
    "                ax1.set_title(\"Detections\")\n",
    "                \n",
    "                # Show masks\n",
    "                ax2.imshow(image)\n",
    "                for mask in masks:\n",
    "                    mask_img = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "                    mask_img[mask > 0] = [255, 0, 0]\n",
    "                    ax2.imshow(mask_img, alpha=0.3)\n",
    "                ax2.set_title(\"Segmentations\")\n",
    "                \n",
    "                plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Detailed error processing image {image_path}:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(f\"Skipping this image and continuing with the next one...\")\n",
    "            continue\n",
    "\n",
    "    # Save COCO dataset to JSON file\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(coco_dataset, f)\n",
    "    \n",
    "    print(f\"\\nProcessing complete. COCO annotations saved to {output_json}\")\n",
    "    print(f\"Total images processed: {len(coco_dataset['images'])}\")\n",
    "    print(f\"Total annotations created: {len(coco_dataset['annotations'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(INITVID_EXTRACT_LOCATION_ANNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images to process\n",
      "\n",
      "Processing image 1/180: frame_0001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence-2 detection results - Boxes: 3, Labels: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Memory efficient kernel not used because: (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:718.)\n",
      "UserWarning: Memory Efficient attention has been runtime disabled. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen/native/transformers/sdp_utils_cpp.h:495.)\n",
      "UserWarning: Flash attention kernel not used because: (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:720.)\n",
      "UserWarning: CuDNN attention kernel not used because: (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:722.)\n",
      "UserWarning: Expected query, key and value to all be of dtype: {Half, BFloat16}. Got Query dtype: float, Key dtype: float, and Value dtype: float instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen/native/transformers/sdp_utils_cpp.h:108.)\n",
      "UserWarning: Flash Attention kernel failed due to: No available kernel. Aborting execution.\n",
      "Falling back to all available kernels for scaled_dot_product_attention (which may have a slower speed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 2/180: frame_0002.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 3/180: frame_0003.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 4/180: frame_0004.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 5/180: frame_0005.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 6/180: frame_0006.jpg\n",
      "Florence-2 detection results - Boxes: 5, Labels: 6\n",
      "SAM2 prediction results - Masks shape: (5, 1, 1440, 1920)\n",
      "\n",
      "Processing image 7/180: frame_0007.jpg\n",
      "Florence-2 detection results - Boxes: 6, Labels: 6\n",
      "SAM2 prediction results - Masks shape: (6, 1, 1440, 1920)\n",
      "\n",
      "Processing image 8/180: frame_0008.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 9/180: frame_0009.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 10/180: frame_0010.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 11/180: frame_0011.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 12/180: frame_0012.jpg\n",
      "Florence-2 detection results - Boxes: 6, Labels: 6\n",
      "SAM2 prediction results - Masks shape: (6, 1, 1440, 1920)\n",
      "\n",
      "Processing image 13/180: frame_0013.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 14/180: frame_0014.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 15/180: frame_0015.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 16/180: frame_0016.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 17/180: frame_0017.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 18/180: frame_0018.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 19/180: frame_0019.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 20/180: frame_0020.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 21/180: frame_0021.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 22/180: frame_0022.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 23/180: frame_0023.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 24/180: frame_0024.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 1\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 25/180: frame_0025.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 26/180: frame_0026.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 27/180: frame_0027.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 28/180: frame_0028.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 29/180: frame_0029.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 30/180: frame_0030.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 31/180: frame_0031.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 32/180: frame_0032.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 33/180: frame_0033.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 34/180: frame_0034.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 35/180: frame_0035.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 36/180: frame_0036.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 37/180: frame_0037.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 38/180: frame_0038.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 39/180: frame_0039.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 40/180: frame_0040.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 41/180: frame_0041.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 42/180: frame_0042.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 43/180: frame_0043.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 44/180: frame_0044.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 45/180: frame_0045.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 46/180: frame_0046.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 47/180: frame_0047.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 48/180: frame_0048.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 49/180: frame_0049.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 50/180: frame_0050.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 51/180: frame_0051.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 52/180: frame_0052.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 53/180: frame_0053.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 54/180: frame_0054.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 55/180: frame_0055.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 56/180: frame_0056.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 57/180: frame_0057.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 58/180: frame_0058.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 59/180: frame_0059.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 60/180: frame_0060.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 61/180: frame_0061.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 62/180: frame_0062.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 63/180: frame_0063.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 64/180: frame_0064.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 65/180: frame_0065.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 66/180: frame_0066.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 67/180: frame_0067.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 1\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 68/180: frame_0068.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 69/180: frame_0069.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 70/180: frame_0070.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 71/180: frame_0071.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 72/180: frame_0072.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 73/180: frame_0073.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 74/180: frame_0074.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 1\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 75/180: frame_0075.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 76/180: frame_0076.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 77/180: frame_0077.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 78/180: frame_0078.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 79/180: frame_0079.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 80/180: frame_0080.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 81/180: frame_0081.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 82/180: frame_0082.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 83/180: frame_0083.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 84/180: frame_0084.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 85/180: frame_0085.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 86/180: frame_0086.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 87/180: frame_0087.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 88/180: frame_0088.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 89/180: frame_0089.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 90/180: frame_0090.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 91/180: frame_0091.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 92/180: frame_0092.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 93/180: frame_0093.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 94/180: frame_0094.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 95/180: frame_0095.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 96/180: frame_0096.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 97/180: frame_0097.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 98/180: frame_0098.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 99/180: frame_0099.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 100/180: frame_0100.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 101/180: frame_0101.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 102/180: frame_0102.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 103/180: frame_0103.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 104/180: frame_0104.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 105/180: frame_0105.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 106/180: frame_0106.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 107/180: frame_0107.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 108/180: frame_0108.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 109/180: frame_0109.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 110/180: frame_0110.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 111/180: frame_0111.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 112/180: frame_0112.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 113/180: frame_0113.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 114/180: frame_0114.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 115/180: frame_0115.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 116/180: frame_0116.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 117/180: frame_0117.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 118/180: frame_0118.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 119/180: frame_0119.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 120/180: frame_0120.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 121/180: frame_0121.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 122/180: frame_0122.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 123/180: frame_0123.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 124/180: frame_0124.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 125/180: frame_0125.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 126/180: frame_0126.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 127/180: frame_0127.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 128/180: frame_0128.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 129/180: frame_0129.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 130/180: frame_0130.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 131/180: frame_0131.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 132/180: frame_0132.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 133/180: frame_0133.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 134/180: frame_0134.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 135/180: frame_0135.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 136/180: frame_0136.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 137/180: frame_0137.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 138/180: frame_0138.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 139/180: frame_0139.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 140/180: frame_0140.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 141/180: frame_0141.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 142/180: frame_0142.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 143/180: frame_0143.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 144/180: frame_0144.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 145/180: frame_0145.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 146/180: frame_0146.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 147/180: frame_0147.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 148/180: frame_0148.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 149/180: frame_0149.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 150/180: frame_0150.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 151/180: frame_0151.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 152/180: frame_0152.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 153/180: frame_0153.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 154/180: frame_0154.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 155/180: frame_0155.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 156/180: frame_0156.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 157/180: frame_0157.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 158/180: frame_0158.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 159/180: frame_0159.jpg\n",
      "Florence-2 detection results - Boxes: 5, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (5, 1, 1440, 1920)\n",
      "\n",
      "Processing image 160/180: frame_0160.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 161/180: frame_0161.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 162/180: frame_0162.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 163/180: frame_0163.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 164/180: frame_0164.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 165/180: frame_0165.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 166/180: frame_0166.jpg\n",
      "Florence-2 detection results - Boxes: 0, Labels: 1\n",
      "\n",
      "Processing image 167/180: frame_0167.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 168/180: frame_0168.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 169/180: frame_0169.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 170/180: frame_0170.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 171/180: frame_0171.jpg\n",
      "Florence-2 detection results - Boxes: 5, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (5, 1, 1440, 1920)\n",
      "\n",
      "Processing image 172/180: frame_0172.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 173/180: frame_0173.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 5\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 174/180: frame_0174.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 175/180: frame_0175.jpg\n",
      "Florence-2 detection results - Boxes: 4, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (4, 1, 1440, 1920)\n",
      "\n",
      "Processing image 176/180: frame_0176.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing image 177/180: frame_0177.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 3\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 178/180: frame_0178.jpg\n",
      "Florence-2 detection results - Boxes: 1, Labels: 1\n",
      "SAM2 prediction results - Masks shape: (1, 1440, 1920)\n",
      "\n",
      "Processing image 179/180: frame_0179.jpg\n",
      "Florence-2 detection results - Boxes: 3, Labels: 4\n",
      "SAM2 prediction results - Masks shape: (3, 1, 1440, 1920)\n",
      "\n",
      "Processing image 180/180: frame_0180.jpg\n",
      "Florence-2 detection results - Boxes: 2, Labels: 2\n",
      "SAM2 prediction results - Masks shape: (2, 1, 1440, 1920)\n",
      "\n",
      "Processing complete. COCO annotations saved to C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\detect_scripts/Waychinicup_train_fish_dataset_coco.json\n",
      "Total images processed: 180\n",
      "Total annotations created: 285\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "input_directory = f\"{AIDIR}/data/Waychinicup_train\"  # Your input directory\n",
    "output_json_file = f\"{AIDIR}/Waychinicup_train_fish_dataset_coco.json\"  # Where to save the COCO json\n",
    "\n",
    "# Run the processing\n",
    "process_directory_to_coco(input_directory, output_json_file, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Segmentation Masks to YOLO Bounding Boxes\n",
    "\n",
    "Once annotations are complete in CVAT, export the annotations in YOLO format. This works properly for Bounding Box annotations, but when segmentation is used, the annotation files are empty. Re-export from CVAT in COCO or CVAT format and copy the annotation JSON or XML file to the same folder as the YOLO files. The following scripts will convert from CVAT/COCO into YOLO.\n",
    "Only one is needed.\n",
    "\n",
    "Set the annotation file to convert from and the folder name to write to. Append obj_train_data to the folder name.\n",
    "- TRAINING_SITE_TYPE = Essentially, the location where the annotation files are saved to. All other variables are updated using this for consistency.\n",
    "- COCO_ANNO_FOLDER = Folder location to coco or cvat annotation file. Script appends relevent file name automatically.\n",
    "- YOLO_ANNO_FOLDER = Folder where YOLO files will be extracted.\n",
    "- IOU_OUTPUT_CSV = File to write YOLO data for each unique fish, in each frame, from YOLO annotation folder.\n",
    "- CLASS_COUNT_CSV = CSV file that contains the total count for each class\n",
    "- DETAILED_ANNO_CSV = CSV file that contains the dimensions of each fish (may be redundant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRDIR: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\n"
     ]
    }
   ],
   "source": [
    "os.chdir(ANNODIR)\n",
    "CURRDIR = os.getcwd()\n",
    "#os.path.join(os.getcwd(), WORKING_DIR)\n",
    "#HOME = 'C:\\\\Users\\\\neez\\\\OneDrive\\\\Uni\\\\VLS301\\\\detect_scripts'\n",
    "#os.chdir(HOME)\n",
    "print(\"CURRDIR:\", CURRDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNODIR: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\n",
      "CURRDIR: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\n",
      "COCO_ANNO_FOLDER: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\n",
      "YOLO_ANNO_FOLDER: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SITE_TYPE = \"Reef_BB\"\n",
    "\n",
    "COCO_ANNO_FOLDER = os.path.join(ANNODIR, TRAINING_SITE_TYPE)\n",
    "YOLO_ANNO_FOLDER = os.path.join(ANNODIR, TRAINING_SITE_TYPE, \"obj_train_data\")\n",
    "IOU_OUTPUT_CSV = os.path.join(ANNODIR, f\"{TRAINING_SITE_TYPE}_IoU.csv\")\n",
    "CLASS_COUNT_CSV = os.path.join(ANNODIR, f\"{TRAINING_SITE_TYPE}_class_counts.csv\")\n",
    "DETAILED_ANNO_CSV = os.path.join(ANNODIR, f\"{TRAINING_SITE_TYPE}_detailed_annotations.csv\")\n",
    "\n",
    "print(\"ANNODIR:\", ANNODIR)\n",
    "print(\"CURRDIR:\", CURRDIR)\n",
    "print(\"COCO_ANNO_FOLDER:\", COCO_ANNO_FOLDER)\n",
    "print(\"YOLO_ANNO_FOLDER:\", YOLO_ANNO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Processed annotation for category 46\n",
      "Conversion complete. YOLO format files saved in C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\obj_train_data\n"
     ]
    }
   ],
   "source": [
    "!python cocomask-to-yolo-conversion.py {COCO_ANNO_FOLDER} {YOLO_ANNO_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python coco-to-yolo-conversion.py {COCO_ANNO_FOLDER} {YOLO_ANNO_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cvat-xml-to-yolo-converter {COCO_ANNO_FOLDER} {YOLO_ANNO_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Annotation Data\n",
    "\n",
    "Point the following to the folder where the images and YOLO annotations are. It will create 2 CSV files, \n",
    "- detailed_annotations = contains the size of the annotation in 1 file (frame #, class id, width, height, area)\n",
    "- class_counts = contains the count of each class for the whole set of images (class id, count)\n",
    "\n",
    "Useage\n",
    "    yolo-annotation-processor.py <dir_name> --class_counts=<class_count.csv> --detailed_annotations=<detailed_annotations.csv>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0001.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0002.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0003.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0004.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0005.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0006.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0007.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0008.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0009.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0010.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0011.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0012.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0013.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0014.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0015.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0016.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0017.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0018.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0019.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0020.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0021.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0022.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0023.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0024.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0025.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0026.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0027.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0028.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0029.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0030.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0031.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0032.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0033.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0034.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0035.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0036.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0037.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0038.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0039.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0040.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0041.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0042.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0043.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0044.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0045.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0046.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0047.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0048.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0049.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0050.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0051.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0052.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0053.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0054.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0055.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0056.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0057.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0058.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0059.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0060.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0061.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0062.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0063.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0064.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0065.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0066.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0067.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0068.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0069.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0070.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0071.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0072.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0073.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0074.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0075.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0076.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0077.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0078.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0079.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0080.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0081.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0082.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0083.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0084.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0085.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0086.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0087.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0088.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0089.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0090.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0091.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0092.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0093.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0094.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0095.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0096.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0097.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0098.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0099.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0100.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0101.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0102.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0103.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0104.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0105.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0106.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0107.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0108.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0109.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0110.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0111.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0112.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0113.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0114.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0115.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0116.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0117.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0118.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0119.txt\n",
      "Processing: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB\\obj_train_data\\frame_0120.txt\n",
      "Class counts written to: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB_class_counts.csv\n",
      "Detailed annotations written to: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Reef_BB_detailed_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "!python yolo-annotation-processor.py {YOLO_ANNO_FOLDER} --class_counts={CLASS_COUNT_CSV} --detailed_annotations={DETAILED_ANNO_CSV}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts IoU data and writes it to a CSV file. This is used for comparing methods. Uses YOLO_ANNO_FILE from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Artreef_FloSam_IoU.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "!python iou_data_extractor.py {YOLO_ANNO_FOLDER} {IOU_OUTPUT_CSV}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find small annotations and intersecting bounding boxes and assign to discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cell - Import required modules and define constants\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "# Constants (you can adjust these if needed)\n",
    "IOU_THRESHOLD = 0.0  # Intersection over Union threshold\n",
    "MIN_BOX_AREA_PERCENT = 0.5  # Minimum box area as a percentage of image area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second cell - Define helper functions\n",
    "def parse_yolo_annotation(line):\n",
    "    class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "    return int(class_id), x_center, y_center, width, height\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    # Convert YOLO format to (x1, y1, x2, y2)\n",
    "    def yolo_to_corners(x_center, y_center, width, height):\n",
    "        x1 = x_center - width / 2\n",
    "        y1 = y_center - height / 2\n",
    "        x2 = x_center + width / 2\n",
    "        y2 = y_center + height / 2\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    box1_corners = yolo_to_corners(*box1[1:])\n",
    "    box2_corners = yolo_to_corners(*box2[1:])\n",
    "\n",
    "    # Calculate intersection area\n",
    "    x_left = max(box1_corners[0], box2_corners[0])\n",
    "    y_top = max(box1_corners[1], box2_corners[1])\n",
    "    x_right = min(box1_corners[2], box2_corners[2])\n",
    "    y_bottom = min(box1_corners[3], box2_corners[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate union area\n",
    "    box1_area = (box1_corners[2] - box1_corners[0]) * (box1_corners[3] - box1_corners[1])\n",
    "    box2_area = (box2_corners[2] - box2_corners[0]) * (box2_corners[3] - box2_corners[1])\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area if union_area > 0 else 0.0\n",
    "    return iou\n",
    "\n",
    "def is_box_too_small(box):\n",
    "    _, _, _, width, height = box\n",
    "    box_area = width * height\n",
    "    return box_area < (MIN_BOX_AREA_PERCENT / 100)\n",
    "\n",
    "def process_yolo_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        annotations = [parse_yolo_annotation(line) for line in f]\n",
    "\n",
    "    boxes_to_discard = set()\n",
    "    \n",
    "    # Check for intersections\n",
    "    for box1, box2 in combinations(annotations, 2):\n",
    "        if calculate_iou(box1, box2) > IOU_THRESHOLD:\n",
    "            boxes_to_discard.add(box1)\n",
    "            boxes_to_discard.add(box2)\n",
    "    \n",
    "    # Check for small boxes\n",
    "    for box in annotations:\n",
    "        if is_box_too_small(box):\n",
    "            boxes_to_discard.add(box)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        for box in annotations:\n",
    "            if box in boxes_to_discard:\n",
    "                f.write(f\"1 {' '.join(map(str, box[1:]))}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{box[0]} {' '.join(map(str, box[1:]))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third cell - Process files using environment variables\n",
    "def process_directory(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all YOLO annotation files in the input directory and save to output directory.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Input directory containing YOLO annotation files\n",
    "        output_dir: Output directory for processed files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    # Get list of txt files\n",
    "    txt_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
    "    print(f\"Found {len(txt_files)} text files to process\")\n",
    "\n",
    "    # Process each file\n",
    "    for filename in txt_files:\n",
    "        input_file = os.path.join(input_dir, filename)\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "        process_yolo_file(input_file, output_file)\n",
    "        print(f\"Processed {filename}\")\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\updated_classes\n",
      "Found 180 images to process\n",
      "Processing frame_0001.jpg...\n",
      "Processing frame_0002.jpg...\n",
      "Processing frame_0003.jpg...\n",
      "Processing frame_0004.jpg...\n",
      "Processing frame_0005.jpg...\n",
      "Processing frame_0006.jpg...\n",
      "Processing frame_0007.jpg...\n",
      "Processing frame_0008.jpg...\n",
      "Processing frame_0009.jpg...\n",
      "Processing frame_0010.jpg...\n",
      "Processing frame_0011.jpg...\n",
      "Processing frame_0012.jpg...\n",
      "Processing frame_0013.jpg...\n",
      "Processing frame_0014.jpg...\n",
      "Processing frame_0015.jpg...\n",
      "Processing frame_0016.jpg...\n",
      "Processing frame_0017.jpg...\n",
      "Processing frame_0018.jpg...\n",
      "Processing frame_0019.jpg...\n",
      "Processing frame_0020.jpg...\n",
      "Processing frame_0021.jpg...\n",
      "Processing frame_0022.jpg...\n",
      "Processing frame_0023.jpg...\n",
      "Processing frame_0024.jpg...\n",
      "No annotation file found for frame_0025.jpg\n",
      "Processing frame_0026.jpg...\n",
      "Processing frame_0027.jpg...\n",
      "Processing frame_0028.jpg...\n",
      "Processing frame_0029.jpg...\n",
      "Processing frame_0030.jpg...\n",
      "No annotation file found for frame_0031.jpg\n",
      "Processing frame_0032.jpg...\n",
      "Processing frame_0033.jpg...\n",
      "No annotation file found for frame_0034.jpg\n",
      "Processing frame_0035.jpg...\n",
      "No annotation file found for frame_0036.jpg\n",
      "No annotation file found for frame_0037.jpg\n",
      "Processing frame_0038.jpg...\n",
      "Processing frame_0039.jpg...\n",
      "No annotation file found for frame_0040.jpg\n",
      "No annotation file found for frame_0041.jpg\n",
      "Processing frame_0042.jpg...\n",
      "No annotation file found for frame_0043.jpg\n",
      "No annotation file found for frame_0044.jpg\n",
      "Processing frame_0045.jpg...\n",
      "No annotation file found for frame_0046.jpg\n",
      "Processing frame_0047.jpg...\n",
      "Processing frame_0048.jpg...\n",
      "Processing frame_0049.jpg...\n",
      "No annotation file found for frame_0050.jpg\n",
      "Processing frame_0051.jpg...\n",
      "No annotation file found for frame_0052.jpg\n",
      "No annotation file found for frame_0053.jpg\n",
      "No annotation file found for frame_0054.jpg\n",
      "Processing frame_0055.jpg...\n",
      "Processing frame_0056.jpg...\n",
      "Processing frame_0057.jpg...\n",
      "Processing frame_0058.jpg...\n",
      "Processing frame_0059.jpg...\n",
      "Processing frame_0060.jpg...\n",
      "Processing frame_0061.jpg...\n",
      "Processing frame_0062.jpg...\n",
      "No annotation file found for frame_0063.jpg\n",
      "Processing frame_0064.jpg...\n",
      "Processing frame_0065.jpg...\n",
      "Processing frame_0066.jpg...\n",
      "Processing frame_0067.jpg...\n",
      "Processing frame_0068.jpg...\n",
      "Processing frame_0069.jpg...\n",
      "Processing frame_0070.jpg...\n",
      "No annotation file found for frame_0071.jpg\n",
      "Processing frame_0072.jpg...\n",
      "No annotation file found for frame_0073.jpg\n",
      "Processing frame_0074.jpg...\n",
      "No annotation file found for frame_0075.jpg\n",
      "Processing frame_0076.jpg...\n",
      "No annotation file found for frame_0077.jpg\n",
      "Processing frame_0078.jpg...\n",
      "Processing frame_0079.jpg...\n",
      "Processing frame_0080.jpg...\n",
      "Processing frame_0081.jpg...\n",
      "No annotation file found for frame_0082.jpg\n",
      "Processing frame_0083.jpg...\n",
      "No annotation file found for frame_0084.jpg\n",
      "Processing frame_0085.jpg...\n",
      "No annotation file found for frame_0086.jpg\n",
      "No annotation file found for frame_0087.jpg\n",
      "Processing frame_0088.jpg...\n",
      "No annotation file found for frame_0089.jpg\n",
      "Processing frame_0090.jpg...\n",
      "Processing frame_0091.jpg...\n",
      "Processing frame_0092.jpg...\n",
      "Processing frame_0093.jpg...\n",
      "Processing frame_0094.jpg...\n",
      "Processing frame_0095.jpg...\n",
      "Processing frame_0096.jpg...\n",
      "Processing frame_0097.jpg...\n",
      "Processing frame_0098.jpg...\n",
      "Processing frame_0099.jpg...\n",
      "Processing frame_0100.jpg...\n",
      "No annotation file found for frame_0101.jpg\n",
      "Processing frame_0102.jpg...\n",
      "Processing frame_0103.jpg...\n",
      "No annotation file found for frame_0104.jpg\n",
      "Processing frame_0105.jpg...\n",
      "No annotation file found for frame_0106.jpg\n",
      "No annotation file found for frame_0107.jpg\n",
      "Processing frame_0108.jpg...\n",
      "No annotation file found for frame_0109.jpg\n",
      "Processing frame_0110.jpg...\n",
      "No annotation file found for frame_0111.jpg\n",
      "Processing frame_0112.jpg...\n",
      "No annotation file found for frame_0113.jpg\n",
      "Processing frame_0114.jpg...\n",
      "Processing frame_0115.jpg...\n",
      "Processing frame_0116.jpg...\n",
      "No annotation file found for frame_0117.jpg\n",
      "No annotation file found for frame_0118.jpg\n",
      "Processing frame_0119.jpg...\n",
      "No annotation file found for frame_0120.jpg\n",
      "Processing frame_0121.jpg...\n",
      "Processing frame_0122.jpg...\n",
      "No annotation file found for frame_0123.jpg\n",
      "Processing frame_0124.jpg...\n",
      "Processing frame_0125.jpg...\n",
      "No annotation file found for frame_0126.jpg\n",
      "Processing frame_0127.jpg...\n",
      "No annotation file found for frame_0128.jpg\n",
      "No annotation file found for frame_0129.jpg\n",
      "Processing frame_0130.jpg...\n",
      "Processing frame_0131.jpg...\n",
      "Processing frame_0132.jpg...\n",
      "Processing frame_0133.jpg...\n",
      "Processing frame_0134.jpg...\n",
      "No annotation file found for frame_0135.jpg\n",
      "No annotation file found for frame_0136.jpg\n",
      "Processing frame_0137.jpg...\n",
      "Processing frame_0138.jpg...\n",
      "No annotation file found for frame_0139.jpg\n",
      "Processing frame_0140.jpg...\n",
      "No annotation file found for frame_0141.jpg\n",
      "No annotation file found for frame_0142.jpg\n",
      "No annotation file found for frame_0143.jpg\n",
      "No annotation file found for frame_0144.jpg\n",
      "No annotation file found for frame_0145.jpg\n",
      "Processing frame_0146.jpg...\n",
      "Processing frame_0147.jpg...\n",
      "Processing frame_0148.jpg...\n",
      "Processing frame_0149.jpg...\n",
      "Processing frame_0150.jpg...\n",
      "Processing frame_0151.jpg...\n",
      "Processing frame_0152.jpg...\n",
      "Processing frame_0153.jpg...\n",
      "Processing frame_0154.jpg...\n",
      "Processing frame_0155.jpg...\n",
      "Processing frame_0156.jpg...\n",
      "Processing frame_0157.jpg...\n",
      "Processing frame_0158.jpg...\n",
      "Processing frame_0159.jpg...\n",
      "Processing frame_0160.jpg...\n",
      "Processing frame_0161.jpg...\n",
      "Processing frame_0162.jpg...\n",
      "Processing frame_0163.jpg...\n",
      "Processing frame_0164.jpg...\n",
      "Processing frame_0165.jpg...\n",
      "No annotation file found for frame_0166.jpg\n",
      "Processing frame_0167.jpg...\n",
      "Processing frame_0168.jpg...\n",
      "Processing frame_0169.jpg...\n",
      "Processing frame_0170.jpg...\n",
      "Processing frame_0171.jpg...\n",
      "Processing frame_0172.jpg...\n",
      "Processing frame_0173.jpg...\n",
      "Processing frame_0174.jpg...\n",
      "Processing frame_0175.jpg...\n",
      "Processing frame_0176.jpg...\n",
      "Processing frame_0177.jpg...\n",
      "Processing frame_0178.jpg...\n",
      "Processing frame_0179.jpg...\n",
      "Processing frame_0180.jpg...\n",
      "\n",
      "Processing complete!\n",
      "Input directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\obj_train_data\n",
      "Output directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\updated_classes\n"
     ]
    }
   ],
   "source": [
    "# Fourth cell - Execute the processing\n",
    "# Define your input and output directories\n",
    "INPUT_DIR = YOLO_ANNO_FOLDER\n",
    "UPDATED_CLASS_DIR = os.path.join(COCO_ANNO_FOLDER, \"updated_classes\")\n",
    "OUTPUT_DIR = UPDATED_CLASS_DIR\n",
    "\n",
    "# Run the processing\n",
    "process_directory(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cell - Imports and basic functions\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def parse_yolo_annotation(line):\n",
    "    class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "    return int(class_id), x_center, y_center, width, height\n",
    "\n",
    "def yolo_to_pixel_coords(box, img_width, img_height):\n",
    "    class_id, x_center, y_center, width, height = box\n",
    "    x1 = int((x_center - width/2) * img_width)\n",
    "    y1 = int((y_center - height/2) * img_height)\n",
    "    x2 = int((x_center + width/2) * img_width)\n",
    "    y2 = int((y_center + height/2) * img_height)\n",
    "    return class_id, x1, y1, x2, y2\n",
    "\n",
    "def pixel_to_yolo_coords(box, img_width, img_height):\n",
    "    class_id, x1, y1, x2, y2 = box\n",
    "    x_center = (x1 + x2) / (2 * img_width)\n",
    "    y_center = (y1 + y2) / (2 * img_height)\n",
    "    width = (x2 - x1) / img_width\n",
    "    height = (y2 - y1) / img_height\n",
    "    return class_id, x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second cell - Define expansion orders and intersection check\n",
    "def intersects(x1, y1, x2, y2, ox1, oy1, ox2, oy2):\n",
    "    return not (x2 < ox1 or ox2 < x1 or y2 < oy1 or oy2 < y1)\n",
    "\n",
    "# Define all possible expansion orders\n",
    "expansion_orders = [\n",
    "    ['left', 'right', 'up', 'down'],\n",
    "    ['left', 'right', 'down', 'up'],\n",
    "    ['left', 'down', 'right', 'up'],\n",
    "    ['left', 'down', 'up', 'right'],\n",
    "    ['left', 'up', 'down', 'right'],\n",
    "    ['left', 'up', 'right', 'down'],\n",
    "    ['right', 'left', 'up', 'down'],\n",
    "    ['right', 'left', 'down', 'up'],\n",
    "    ['right', 'down', 'left', 'up'],\n",
    "    ['right', 'down', 'up', 'left'],\n",
    "    ['right', 'up', 'down', 'left'],\n",
    "    ['right', 'up', 'left', 'down'],\n",
    "    ['up', 'right', 'left', 'down'],\n",
    "    ['up', 'right', 'down', 'left'],\n",
    "    ['up', 'down', 'right', 'left'],\n",
    "    ['up', 'down', 'left', 'right'],\n",
    "    ['up', 'left', 'down', 'right'],\n",
    "    ['up', 'left', 'right', 'down'],\n",
    "    ['down', 'left', 'up', 'right'],\n",
    "    ['down', 'left', 'right', 'up'],\n",
    "    ['down', 'right', 'left', 'up'],\n",
    "    ['down', 'right', 'up', 'left'],\n",
    "    ['down', 'up', 'right', 'left'],\n",
    "    ['down', 'up', 'left', 'right']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third cell - Cropping function\n",
    "def crop_image(image, target_box, other_boxes, margin_factor=0.2):\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    class_id, tx1, ty1, tx2, ty2 = target_box\n",
    "\n",
    "    # Calculate margins\n",
    "    margin_x = int((tx2 - tx1) * margin_factor)\n",
    "    margin_y = int((ty2 - ty1) * margin_factor)\n",
    "\n",
    "    # Initialize crop to target box with margins\n",
    "    cx1 = max(0, tx1 - margin_x)\n",
    "    cy1 = max(0, ty1 - margin_y)\n",
    "    cx2 = min(img_width, tx2 + margin_x)\n",
    "    cy2 = min(img_height, ty2 + margin_y)\n",
    "\n",
    "    def expand_direction(x1, y1, x2, y2, direction):\n",
    "        while True:\n",
    "            if direction == 'left' and x1 > 0:\n",
    "                new_x1 = x1 - 1\n",
    "                if any(intersects(new_x1, y1, x2, y2, *box[1:]) for box in other_boxes if box[0] != class_id):\n",
    "                    break\n",
    "                x1 = new_x1\n",
    "            elif direction == 'right' and x2 < img_width:\n",
    "                new_x2 = x2 + 1\n",
    "                if any(intersects(x1, y1, new_x2, y2, *box[1:]) for box in other_boxes if box[0] != class_id):\n",
    "                    break\n",
    "                x2 = new_x2\n",
    "            elif direction == 'up' and y1 > 0:\n",
    "                new_y1 = y1 - 1\n",
    "                if any(intersects(x1, new_y1, x2, y2, *box[1:]) for box in other_boxes if box[0] != class_id):\n",
    "                    break\n",
    "                y1 = new_y1\n",
    "            elif direction == 'down' and y2 < img_height:\n",
    "                new_y2 = y2 + 1\n",
    "                if any(intersects(x1, y1, x2, new_y2, *box[1:]) for box in other_boxes if box[0] != class_id):\n",
    "                    break\n",
    "                y2 = new_y2\n",
    "            else:\n",
    "                break\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    best_crop = None\n",
    "    max_area = 0\n",
    "\n",
    "    for order in expansion_orders:\n",
    "        temp_cx1, temp_cy1, temp_cx2, temp_cy2 = cx1, cy1, cx2, cy2\n",
    "        for direction in order:\n",
    "            temp_cx1, temp_cy1, temp_cx2, temp_cy2 = expand_direction(temp_cx1, temp_cy1, temp_cx2, temp_cy2, direction)\n",
    "        \n",
    "        area = (temp_cx2 - temp_cx1) * (temp_cy2 - temp_cy1)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            best_crop = (temp_cx1, temp_cy1, temp_cx2, temp_cy2)\n",
    "\n",
    "    cx1, cy1, cx2, cy2 = best_crop\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[int(cy1):int(cy2), int(cx1):int(cx2)]\n",
    "\n",
    "    # Adjust bounding box coordinates for the cropped image\n",
    "    new_box = (class_id, tx1 - cx1, ty1 - cy1, tx2 - cx1, ty2 - cy1)\n",
    "\n",
    "    return cropped_image, new_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth cell - File processing function\n",
    "def process_file(image_path, annotation_path, output_dir):\n",
    "    # Read image and annotations\n",
    "    image = cv2.imread(image_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        annotations = [parse_yolo_annotation(line) for line in f]\n",
    "\n",
    "    # Convert YOLO coords to pixel coords\n",
    "    pixel_annotations = [yolo_to_pixel_coords(box, img_width, img_height) for box in annotations]\n",
    "\n",
    "    # Process each object\n",
    "    for i, target_box in enumerate(pixel_annotations):\n",
    "        other_boxes = [box for box in pixel_annotations if box != target_box]\n",
    "        \n",
    "        cropped_image, new_box = crop_image(image, target_box, other_boxes)\n",
    "\n",
    "        # Generate new filenames\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        class_id = target_box[0]\n",
    "        new_image_name = f\"{class_id}_{base_name}_{i+1:02d}.jpg\"\n",
    "        new_anno_name = f\"{class_id}_{base_name}_{i+1:02d}.txt\"\n",
    "\n",
    "        # Create class subdirectory if it doesn't exist\n",
    "        class_dir = os.path.join(output_dir, str(class_id))\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Save cropped image\n",
    "        cv2.imwrite(os.path.join(class_dir, new_image_name), cropped_image)\n",
    "\n",
    "        # Save new annotation\n",
    "        crop_height, crop_width = cropped_image.shape[:2]\n",
    "        new_yolo_box = pixel_to_yolo_coords(new_box, crop_width, crop_height)\n",
    "        with open(os.path.join(class_dir, new_anno_name), 'w') as f:\n",
    "            f.write(f\"{new_yolo_box[0]} {new_yolo_box[1]} {new_yolo_box[2]} {new_yolo_box[3]} {new_yolo_box[4]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\updated_classes\\cropped\n",
      "Found 180 images to process\n",
      "Processing frame_0001.jpg...\n",
      "Processing frame_0002.jpg...\n",
      "Processing frame_0003.jpg...\n",
      "Processing frame_0004.jpg...\n",
      "Processing frame_0005.jpg...\n",
      "Processing frame_0006.jpg...\n",
      "Processing frame_0007.jpg...\n",
      "Processing frame_0008.jpg...\n",
      "Processing frame_0009.jpg...\n",
      "Processing frame_0010.jpg...\n",
      "Processing frame_0011.jpg...\n",
      "Processing frame_0012.jpg...\n",
      "Processing frame_0013.jpg...\n",
      "Processing frame_0014.jpg...\n",
      "Processing frame_0015.jpg...\n",
      "Processing frame_0016.jpg...\n",
      "Processing frame_0017.jpg...\n",
      "Processing frame_0018.jpg...\n",
      "Processing frame_0019.jpg...\n",
      "Processing frame_0020.jpg...\n",
      "Processing frame_0021.jpg...\n",
      "Processing frame_0022.jpg...\n",
      "Processing frame_0023.jpg...\n",
      "Processing frame_0024.jpg...\n",
      "No annotation file found for frame_0025.jpg\n",
      "Processing frame_0026.jpg...\n",
      "Processing frame_0027.jpg...\n",
      "Processing frame_0028.jpg...\n",
      "Processing frame_0029.jpg...\n",
      "Processing frame_0030.jpg...\n",
      "No annotation file found for frame_0031.jpg\n",
      "Processing frame_0032.jpg...\n",
      "Processing frame_0033.jpg...\n",
      "No annotation file found for frame_0034.jpg\n",
      "Processing frame_0035.jpg...\n",
      "No annotation file found for frame_0036.jpg\n",
      "No annotation file found for frame_0037.jpg\n",
      "Processing frame_0038.jpg...\n",
      "Processing frame_0039.jpg...\n",
      "No annotation file found for frame_0040.jpg\n",
      "No annotation file found for frame_0041.jpg\n",
      "Processing frame_0042.jpg...\n",
      "No annotation file found for frame_0043.jpg\n",
      "No annotation file found for frame_0044.jpg\n",
      "Processing frame_0045.jpg...\n",
      "No annotation file found for frame_0046.jpg\n",
      "Processing frame_0047.jpg...\n",
      "Processing frame_0048.jpg...\n",
      "Processing frame_0049.jpg...\n",
      "No annotation file found for frame_0050.jpg\n",
      "Processing frame_0051.jpg...\n",
      "No annotation file found for frame_0052.jpg\n",
      "No annotation file found for frame_0053.jpg\n",
      "No annotation file found for frame_0054.jpg\n",
      "Processing frame_0055.jpg...\n",
      "Processing frame_0056.jpg...\n",
      "Processing frame_0057.jpg...\n",
      "Processing frame_0058.jpg...\n",
      "Processing frame_0059.jpg...\n",
      "Processing frame_0060.jpg...\n",
      "Processing frame_0061.jpg...\n",
      "Processing frame_0062.jpg...\n",
      "No annotation file found for frame_0063.jpg\n",
      "Processing frame_0064.jpg...\n",
      "Processing frame_0065.jpg...\n",
      "Processing frame_0066.jpg...\n",
      "Processing frame_0067.jpg...\n",
      "Processing frame_0068.jpg...\n",
      "Processing frame_0069.jpg...\n",
      "Processing frame_0070.jpg...\n",
      "No annotation file found for frame_0071.jpg\n",
      "Processing frame_0072.jpg...\n",
      "No annotation file found for frame_0073.jpg\n",
      "Processing frame_0074.jpg...\n",
      "No annotation file found for frame_0075.jpg\n",
      "Processing frame_0076.jpg...\n",
      "No annotation file found for frame_0077.jpg\n",
      "Processing frame_0078.jpg...\n",
      "Processing frame_0079.jpg...\n",
      "Processing frame_0080.jpg...\n",
      "Processing frame_0081.jpg...\n",
      "No annotation file found for frame_0082.jpg\n",
      "Processing frame_0083.jpg...\n",
      "No annotation file found for frame_0084.jpg\n",
      "Processing frame_0085.jpg...\n",
      "No annotation file found for frame_0086.jpg\n",
      "No annotation file found for frame_0087.jpg\n",
      "Processing frame_0088.jpg...\n",
      "No annotation file found for frame_0089.jpg\n",
      "Processing frame_0090.jpg...\n",
      "Processing frame_0091.jpg...\n",
      "Processing frame_0092.jpg...\n",
      "Processing frame_0093.jpg...\n",
      "Processing frame_0094.jpg...\n",
      "Processing frame_0095.jpg...\n",
      "Processing frame_0096.jpg...\n",
      "Processing frame_0097.jpg...\n",
      "Processing frame_0098.jpg...\n",
      "Processing frame_0099.jpg...\n",
      "Processing frame_0100.jpg...\n",
      "No annotation file found for frame_0101.jpg\n",
      "Processing frame_0102.jpg...\n",
      "Processing frame_0103.jpg...\n",
      "No annotation file found for frame_0104.jpg\n",
      "Processing frame_0105.jpg...\n",
      "No annotation file found for frame_0106.jpg\n",
      "No annotation file found for frame_0107.jpg\n",
      "Processing frame_0108.jpg...\n",
      "No annotation file found for frame_0109.jpg\n",
      "Processing frame_0110.jpg...\n",
      "No annotation file found for frame_0111.jpg\n",
      "Processing frame_0112.jpg...\n",
      "No annotation file found for frame_0113.jpg\n",
      "Processing frame_0114.jpg...\n",
      "Processing frame_0115.jpg...\n",
      "Processing frame_0116.jpg...\n",
      "No annotation file found for frame_0117.jpg\n",
      "No annotation file found for frame_0118.jpg\n",
      "Processing frame_0119.jpg...\n",
      "No annotation file found for frame_0120.jpg\n",
      "Processing frame_0121.jpg...\n",
      "Processing frame_0122.jpg...\n",
      "No annotation file found for frame_0123.jpg\n",
      "Processing frame_0124.jpg...\n",
      "Processing frame_0125.jpg...\n",
      "No annotation file found for frame_0126.jpg\n",
      "Processing frame_0127.jpg...\n",
      "No annotation file found for frame_0128.jpg\n",
      "No annotation file found for frame_0129.jpg\n",
      "Processing frame_0130.jpg...\n",
      "Processing frame_0131.jpg...\n",
      "Processing frame_0132.jpg...\n",
      "Processing frame_0133.jpg...\n",
      "Processing frame_0134.jpg...\n",
      "No annotation file found for frame_0135.jpg\n",
      "No annotation file found for frame_0136.jpg\n",
      "Processing frame_0137.jpg...\n",
      "Processing frame_0138.jpg...\n",
      "No annotation file found for frame_0139.jpg\n",
      "Processing frame_0140.jpg...\n",
      "No annotation file found for frame_0141.jpg\n",
      "No annotation file found for frame_0142.jpg\n",
      "No annotation file found for frame_0143.jpg\n",
      "No annotation file found for frame_0144.jpg\n",
      "No annotation file found for frame_0145.jpg\n",
      "Processing frame_0146.jpg...\n",
      "Processing frame_0147.jpg...\n",
      "Processing frame_0148.jpg...\n",
      "Processing frame_0149.jpg...\n",
      "Processing frame_0150.jpg...\n",
      "Processing frame_0151.jpg...\n",
      "Processing frame_0152.jpg...\n",
      "Processing frame_0153.jpg...\n",
      "Processing frame_0154.jpg...\n",
      "Processing frame_0155.jpg...\n",
      "Processing frame_0156.jpg...\n",
      "Processing frame_0157.jpg...\n",
      "Processing frame_0158.jpg...\n",
      "Processing frame_0159.jpg...\n",
      "Processing frame_0160.jpg...\n",
      "Processing frame_0161.jpg...\n",
      "Processing frame_0162.jpg...\n",
      "Processing frame_0163.jpg...\n",
      "Processing frame_0164.jpg...\n",
      "Processing frame_0165.jpg...\n",
      "No annotation file found for frame_0166.jpg\n",
      "Processing frame_0167.jpg...\n",
      "Processing frame_0168.jpg...\n",
      "Processing frame_0169.jpg...\n",
      "Processing frame_0170.jpg...\n",
      "Processing frame_0171.jpg...\n",
      "Processing frame_0172.jpg...\n",
      "Processing frame_0173.jpg...\n",
      "Processing frame_0174.jpg...\n",
      "Processing frame_0175.jpg...\n",
      "Processing frame_0176.jpg...\n",
      "Processing frame_0177.jpg...\n",
      "Processing frame_0178.jpg...\n",
      "Processing frame_0179.jpg...\n",
      "Processing frame_0180.jpg...\n",
      "\n",
      "Processing complete!\n",
      "Input directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\updated_classes\n",
      "Output directory: C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\Completed_Annotations\\Waych1fp20s\\updated_classes\\cropped\n"
     ]
    }
   ],
   "source": [
    "# Fifth cell - Process all files using environment variables\n",
    "def process_directory(input_dir, output_dir):\n",
    "    \"\"\"Process all images and annotations in the input directory.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "    # Process each file\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        annotation_path = os.path.join(input_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            print(f\"Processing {filename}...\")\n",
    "            process_file(image_path, annotation_path, output_dir)\n",
    "        else:\n",
    "            print(f\"No annotation file found for {filename}\")\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Set up input and output directories using environment variables\n",
    "INPUT_DIR = UPDATED_CLASS_DIR\n",
    "OUTPUT_DIR = os.path.join(UPDATED_CLASS_DIR, \"cropped\")\n",
    "\n",
    "# Run the processing\n",
    "process_directory(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\detect_scripts\n"
     ]
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "print(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\detect_scripts\\yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21.5M/21.5M [00:03<00:00, 6.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
      "image 1/1 C:\\Users\\neez\\OneDrive\\Uni\\VLS301\\detect_scripts\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 handbag, 186.7ms\n",
      "Speed: 1.0ms preprocess, 186.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(f'{CWD}/yolov8s.pt')\n",
    "results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PT=YOLO(f'{CWD}/yolov8s.pt')\n",
    "DET_CONF=0.7\n",
    "DET_IOU=0.7\n",
    "DET_PROJECT=TRAINING_SITE_TYPE\n",
    "DET_SOURCE="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo task=detect mode=predict model={MODEL_PT} conf={DET_CONF} SOURCE={DET_SOURCE} project={DET_PROJECT} name=\"detection\" iou={DET_IOU} save_txt=True exist_ok=True save=True imgsz=1280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "The below script hasn't been tested in this notebook and has only been used as a standalone script. It needs modification to work.\n",
    "This script reads through the annotation files created by YOLO inference. Data is collected to create tables for species accumulation curves and MaxN.\n",
    "Because we've extracted frames at 2fps above, we should be able to get a species accumulation curve and MaxN down to 0.5 sec accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import argparse\n",
    "\n",
    "# Create an argument parser\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('--folder', type=str, help='The folder location to find the labels folder')\n",
    "parser.add_argument('--data', type=str, help='The file location of the data.yaml')\n",
    "parser.add_argument('--fps', type=float, help='The frame rate')\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Now you can use args.folder, args.data, args.fps, and args.video in your script\n",
    "str_folder = args.folder\n",
    "data_file = args.data\n",
    "fps = args.fps\n",
    "#video_file = args.video\n",
    "\n",
    "# Open the video file\n",
    "#cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Create an empty dictionary to store the class counts for each file\n",
    "class_counts = {}\n",
    "# Create an empty dictionary to store the first discovery time for each class\n",
    "first_discovery = {}\n",
    "\n",
    "# Loop through the files in the folder\n",
    "files = os.listdir(str_folder)\n",
    "# Sort files by timecode\n",
    "files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "for file in files:\n",
    "    # Read the report file as a pandas dataframe\n",
    "    df = pd.read_csv(os.path.join(str_folder, file), sep=\" \", header=None)\n",
    "    # Rename the columns according to the yolov5 format\n",
    "    df.columns = [\"class\",\"xcenter\", \"ycenter\", \"width\", \"height\"]\n",
    "    # Group the dataframe by the class column and count the number of rows\n",
    "    counts = df.groupby(\"class\").size()\n",
    "    # Convert the counts to a dictionary and store it in the class_counts dictionary with the file name as the key\n",
    "    class_counts[file] = counts.to_dict()\n",
    "\n",
    "    # Update the first_discovery dictionary\n",
    "    for cls in df[\"class\"].unique():\n",
    "        if cls not in first_discovery:\n",
    "            frame_number = int(file.split('_')[-1].split('.')[0])\n",
    "            minutes, seconds = divmod(frame_number / fps, 60)\n",
    "            timestamp = f\"{int(minutes)}:{int(seconds):02d}\"\n",
    "            first_discovery[cls] = timestamp\n",
    "\n",
    "\n",
    "# Create an empty dictionary to store the file name with the highest count for each class\n",
    "max_counts = {}\n",
    "\n",
    "# Loop through the files in the class_counts dictionary\n",
    "for fname, counts in class_counts.items():\n",
    "    # Loop through the classes and counts in the counts dictionary\n",
    "    for cls, count in counts.items():\n",
    "        # If the class is not in the max_counts dictionary or the count is higher than the current maximum\n",
    "        if cls not in max_counts or count > max_counts[cls][1]:\n",
    "            # Update the max_counts dictionary with the file name and the count as a tuple\n",
    "            max_counts[cls] = (fname, count)\n",
    "\n",
    "# Load the data.yaml file and get the class names\n",
    "with open(data_file, \"r\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "class_names = data[\"names\"]\n",
    "\n",
    "# Print the results and write them to a file\n",
    "with open(os.path.join(os.path.dirname(str_folder), 'MaxN results.txt'), 'w') as f, \\\n",
    "     open(os.path.join(os.path.dirname(str_folder), 'Discovery times.txt'), 'w') as g, \\\n",
    "     open(os.path.join(os.path.dirname(str_folder), 'Frame_and_class_ID.txt'), 'w') as h:\n",
    "    print(\"The file with the highest count for each class is:\", file=f)\n",
    "    print(\"The first discovery time for each class is:\", file=g)\n",
    "#    print(\"The frame number and class ID for each class is:\", file=h)\n",
    "    for cls, (file, count) in max_counts.items():\n",
    "        # Extract the frame number from the filename\n",
    "        frame_number = int(file.split('_')[-1].split('.')[0])\n",
    "        # Convert the frame number to a timestamp\n",
    "        minutes, seconds = divmod(frame_number / fps, 60)\n",
    "        timestamp = f\"{int(minutes)}:{int(seconds):02d}\"\n",
    "        # Use the class names instead of the class numbers\n",
    "        result = f\"Class {class_names[cls]}: {timestamp} with {count} objects\"\n",
    "        print(result, file=f)\n",
    "        print(f\"{cls} {frame_number} {class_names[cls]}\", file=h)\n",
    "\n",
    "        # Print the first discovery time for each class\n",
    "        if cls in first_discovery:\n",
    "            print(f\"Class {class_names[cls]} was first discovered at {first_discovery[cls]}\", file=g)\n",
    "\n",
    "        # Set the current position of the video file to the specified frame\n",
    "        #cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        # Read the frame from the video file\n",
    "        #ret, frame = cap.read()\n",
    "\n",
    "        # If the frame was read successfully, save it as an image\n",
    "        #if ret:\n",
    "        #    cv2.imwrite(os.path.join(os.path.dirname(str_folder), f'{class_names[cls]}_frame.jpg'), frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grand Plan\n",
    "The plan is to turn MaxN into a tight histogram, or maybe some formula. This will be used to overlay on a search bar for a video player interface. The idea is to have a curve per species, similar to the YouTube most replayed feature that will give a visual representation of where MaxN is. This will allowed rapid location in the video for manual verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Script to turn MaxN into an image or formual to use in video interface"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0310dd136fa54b06886b254c2f3ef0cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7c27309edad468d946975b620e0b659",
      "max": 51,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d80378f864444af945fc3599c3f65b1",
      "value": 51
     }
    },
    "0409bace810b4653bb278dd7d8dd3597": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0411989350ff48248062361fc129433a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07481c2fd67e4fc2bd0adf74035a5f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bc18d57f0334101b7f2975f4400722c",
      "placeholder": "",
      "style": "IPY_MODEL_651778e0e2494e858889cd36a51ac315",
      "value": "1.10M/1.10M[00:00&lt;00:00,24.2MB/s]"
     }
    },
    "077a1fcc8a14437c96b9b61bea0e02b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c84ab06afe1948a9be90109f20c8d3aa",
      "placeholder": "",
      "style": "IPY_MODEL_88ed1766b43f4c3abeabb6a7432b2512",
      "value": "127k/127k[00:00&lt;00:00,3.60MB/s]"
     }
    },
    "08ce0d91d81c41cf95d3f0fb81352910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b8bb4acd00e40008230d5b94102d092",
      "max": 34,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3697e80878094c8099aecdc947a598e1",
      "value": 34
     }
    },
    "0b8bb4acd00e40008230d5b94102d092": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bc18d57f0334101b7f2975f4400722c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d519131d12b4e07ac25885ff432ed69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e717f61ffc94c99bf7ea9afd588a7ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f051e89ae8e452ab40414a7c9381e12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0411989350ff48248062361fc129433a",
      "max": 806,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8250a63ed0745b7bf4800dcc64853db",
      "value": 806
     }
    },
    "11212eab35a343e7a7e84721af597376": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "145f810b2fbf4ddeb01054e281a1e4f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1500161f52c04cc9a758d34c3e1148d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d38210d8fde4ff89f5febf86ae6f4fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20e838e97d564e7583db5a606b43fb2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "246a0e46d36d4d1182621bc58128faa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_873692b38c4b472da0c017fe58c66b1a",
      "placeholder": "",
      "style": "IPY_MODEL_b3a35db5b4954c6fbfccef0ad3f80659",
      "value": "806/806[00:00&lt;00:00,66.3kB/s]"
     }
    },
    "257c4273556e426c846042927d24953c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "270b2ddf3a834008be92b6f8c6538f57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_448e93a9a1f6473994cafcf90e026320",
      "max": 15125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c48b2b947d34ef498dc4404359a0556",
      "value": 15125
     }
    },
    "275a1f0fa21542b3b71c800dc60eb266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b080ac78fd5d4619970ea696649ab392",
      "placeholder": "",
      "style": "IPY_MODEL_51ea070acb5346e7a9643e62002bc868",
      "value": "tokenizer_config.json:100%"
     }
    },
    "27a07653034f41d5a0ffac79c70b7ecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_559e902f6e3b4e47bbdf631f8a35d62b",
      "placeholder": "",
      "style": "IPY_MODEL_5b2aee580af749988850fe07216a9b50",
      "value": "generation_config.json:100%"
     }
    },
    "282998972a5747b8bbd2484ad2351e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27a07653034f41d5a0ffac79c70b7ecf",
       "IPY_MODEL_0310dd136fa54b06886b254c2f3ef0cb",
       "IPY_MODEL_29a70a9ed82f4ae5a0dc6c5f356c6841"
      ],
      "layout": "IPY_MODEL_fc5fe0bea7e94e38ab66bbe43edc28b6"
     }
    },
    "28cfc14aca97433f882c9deb5398a03e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2920875af6a5405eb5345db9e3585a2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29a70a9ed82f4ae5a0dc6c5f356c6841": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaafcb3b2cbc42d3bf81539f9a42ead9",
      "placeholder": "",
      "style": "IPY_MODEL_145f810b2fbf4ddeb01054e281a1e4f9",
      "value": "51.0/51.0[00:00&lt;00:00,4.38kB/s]"
     }
    },
    "2d4e1bfcf0b34efd866c199086942f6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d38210d8fde4ff89f5febf86ae6f4fc",
      "placeholder": "",
      "style": "IPY_MODEL_a162c364c61349e4950f72e3c2bef4ff",
      "value": "34.0/34.0[00:00&lt;00:00,2.77kB/s]"
     }
    },
    "2e89bd0094bc4eeeb2c4aa077a32c7e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3697e80878094c8099aecdc947a598e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "376fe8e540ae43ad807df362de36dc9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47cd8c0bd53f4d8cb309637242333c00",
      "max": 1543106435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c030d8a53dcb443a9d0aa5d98e543632",
      "value": 1543106435
     }
    },
    "38cd83e638134e69b4c1dcbdba286688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d519131d12b4e07ac25885ff432ed69",
      "placeholder": "",
      "style": "IPY_MODEL_57e8e374a2be448d8b062f53a4d99b02",
      "value": "tokenizer.json:100%"
     }
    },
    "394a13b7f49f4d70b7ebd7ea6f5924ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e717f61ffc94c99bf7ea9afd588a7ac",
      "max": 127219,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1cae4b0a04f4344ae8e50ef9a5db948",
      "value": 127219
     }
    },
    "3954fa1c2ad448e7934111d8f698c521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f0f0c4ebaee428e984955ce5e87a3ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f3730a17c9841e4b726e444f0e361a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8518e339120b4fac82ce72c4919b2fb8",
      "placeholder": "",
      "style": "IPY_MODEL_ca6aefb7f2fe4143a7dd2cde1a40255b",
      "value": "1.36M/1.36M[00:00&lt;00:00,21.3MB/s]"
     }
    },
    "3fa78570b3db434b9aeb37d3baf200af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e91cf2a01c64e2086ad7c8dc859955e",
      "placeholder": "",
      "style": "IPY_MODEL_535295b7f27c4b57885f33a06636a009",
      "value": "1.54G/1.54G[00:08&lt;00:00,185MB/s]"
     }
    },
    "448e93a9a1f6473994cafcf90e026320": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4510d1cab9be4398a5f68df83ca7065e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bb1b68ab33e47789f854e9dcc4e65ee",
       "IPY_MODEL_0f051e89ae8e452ab40414a7c9381e12",
       "IPY_MODEL_246a0e46d36d4d1182621bc58128faa4"
      ],
      "layout": "IPY_MODEL_81f9a42c24cb4d94b45137debad99f42"
     }
    },
    "4778076a30cb4772be7a1cedd5341020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11212eab35a343e7a7e84721af597376",
      "max": 46372,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f302ad2b2fd43aa8158670eb4e59acc",
      "value": 46372
     }
    },
    "47cd8c0bd53f4d8cb309637242333c00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bb1b68ab33e47789f854e9dcc4e65ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ac408daa5b74b0f8fe5a9f299d24188",
      "placeholder": "",
      "style": "IPY_MODEL_c44a7838338341a3a845680d2ab1341a",
      "value": "preprocessor_config.json:100%"
     }
    },
    "4e91cf2a01c64e2086ad7c8dc859955e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f302ad2b2fd43aa8158670eb4e59acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51ea070acb5346e7a9643e62002bc868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "535295b7f27c4b57885f33a06636a009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "537bc6c96deb4ab1bf0c8e6c4b1451ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "559e902f6e3b4e47bbdf631f8a35d62b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c86ad23dba49ef9527c45f6baec402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a93569e9f044cbb2f9e8ddd6d12e06",
      "placeholder": "",
      "style": "IPY_MODEL_e64b1ac4a7b848ceaa4c4725afc944bf",
      "value": "vocab.json:100%"
     }
    },
    "56d6534201d640a58fd697c70b2d6d9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_275a1f0fa21542b3b71c800dc60eb266",
       "IPY_MODEL_08ce0d91d81c41cf95d3f0fb81352910",
       "IPY_MODEL_2d4e1bfcf0b34efd866c199086942f6d"
      ],
      "layout": "IPY_MODEL_3f0f0c4ebaee428e984955ce5e87a3ec"
     }
    },
    "57d36825e7124ebe961876d1693b576a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7eb97169f1d142f0b78823a436933d20",
       "IPY_MODEL_b1d352743b1c434f8313702135584076",
       "IPY_MODEL_fa631ad069154a899fa46c02a0d3a8c4"
      ],
      "layout": "IPY_MODEL_2920875af6a5405eb5345db9e3585a2b"
     }
    },
    "57e8e374a2be448d8b062f53a4d99b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b2aee580af749988850fe07216a9b50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bddf4d19635405d962597d13008d73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad9cad15cfcc44af87bea293836573ad",
       "IPY_MODEL_270b2ddf3a834008be92b6f8c6538f57",
       "IPY_MODEL_8ae3c9792abc450081d38953603c8deb"
      ],
      "layout": "IPY_MODEL_f88034dc172a47e0b980cad80c657bb3"
     }
    },
    "6184c726f8c846328125098b30a75d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "629fd09a98b546adb8ffc4a66a9664ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "651778e0e2494e858889cd36a51ac315": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6abbd8c3305749b6a70ca2667e7c12fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bda44ac5376a419989f2e4165588dcc8",
       "IPY_MODEL_4778076a30cb4772be7a1cedd5341020",
       "IPY_MODEL_7827386dffab4c2fb5ba977e7f34bdde"
      ],
      "layout": "IPY_MODEL_1500161f52c04cc9a758d34c3e1148d4"
     }
    },
    "71a62d265204456ebbce0bac2d7cbf8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "747024b3473d465b85109294fd926238": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7827386dffab4c2fb5ba977e7f34bdde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94d91a7054af4da1806d2ece8eb552cd",
      "placeholder": "",
      "style": "IPY_MODEL_28cfc14aca97433f882c9deb5398a03e",
      "value": "46.4k/46.4k[00:00&lt;00:00,3.69MB/s]"
     }
    },
    "7ac408daa5b74b0f8fe5a9f299d24188": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cb50a8d6c3f42769fcbd2740bcccc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0409bace810b4653bb278dd7d8dd3597",
      "max": 1099884,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f884d62dbdd6491e95d690fc9020e491",
      "value": 1099884
     }
    },
    "7d2af33b8e0c4198aef64a56b20ca1eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eb97169f1d142f0b78823a436933d20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71a62d265204456ebbce0bac2d7cbf8b",
      "placeholder": "",
      "style": "IPY_MODEL_a27ecd3682c6474db9b94426bcf2a0f4",
      "value": "config.json:100%"
     }
    },
    "81f9a42c24cb4d94b45137debad99f42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8518e339120b4fac82ce72c4919b2fb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8603dc2bb7794c64b66e29c9cf1ea2d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90e7da0409264624b65720f3138f9130",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bded8c3ec2b74be4b20cbf8a46d1e97e",
      "value": 1355863
     }
    },
    "873692b38c4b472da0c017fe58c66b1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ed1766b43f4c3abeabb6a7432b2512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ae3c9792abc450081d38953603c8deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_257c4273556e426c846042927d24953c",
      "placeholder": "",
      "style": "IPY_MODEL_6184c726f8c846328125098b30a75d67",
      "value": "15.1k/15.1k[00:00&lt;00:00,1.24MB/s]"
     }
    },
    "8d80378f864444af945fc3599c3f65b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8fc68b03c5dc4ef38b94de606269a1f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56c86ad23dba49ef9527c45f6baec402",
       "IPY_MODEL_7cb50a8d6c3f42769fcbd2740bcccc0d",
       "IPY_MODEL_07481c2fd67e4fc2bd0adf74035a5f1c"
      ],
      "layout": "IPY_MODEL_cdccc14b5a2a4e59b88c191f3f19e38e"
     }
    },
    "90e7da0409264624b65720f3138f9130": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94d91a7054af4da1806d2ece8eb552cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99a93569e9f044cbb2f9e8ddd6d12e06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c48b2b947d34ef498dc4404359a0556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f5ceeccc60b43a3bdd74335b5bea26e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef42b603953647af94ef83a0e992a1b0",
       "IPY_MODEL_376fe8e540ae43ad807df362de36dc9c",
       "IPY_MODEL_3fa78570b3db434b9aeb37d3baf200af"
      ],
      "layout": "IPY_MODEL_a987f90ef00344119b5f98601a26cb6e"
     }
    },
    "a162c364c61349e4950f72e3c2bef4ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1cae4b0a04f4344ae8e50ef9a5db948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a27ecd3682c6474db9b94426bcf2a0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a987f90ef00344119b5f98601a26cb6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9cad15cfcc44af87bea293836573ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdcc974c39bb4eef807565b213b24549",
      "placeholder": "",
      "style": "IPY_MODEL_3954fa1c2ad448e7934111d8f698c521",
      "value": "configuration_florence2.py:100%"
     }
    },
    "b080ac78fd5d4619970ea696649ab392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1d352743b1c434f8313702135584076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e89bd0094bc4eeeb2c4aa077a32c7e2",
      "max": 2445,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f80e27fc19864adc9eccaeb8fb947138",
      "value": 2445
     }
    },
    "b3a35db5b4954c6fbfccef0ad3f80659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6f69234b4974985a30dc9a40e686eb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7c27309edad468d946975b620e0b659": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8250a63ed0745b7bf4800dcc64853db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bda44ac5376a419989f2e4165588dcc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_537bc6c96deb4ab1bf0c8e6c4b1451ab",
      "placeholder": "",
      "style": "IPY_MODEL_f4107cdf82f446ff88ac544487aedd4e",
      "value": "processing_florence2.py:100%"
     }
    },
    "bded8c3ec2b74be4b20cbf8a46d1e97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c030d8a53dcb443a9d0aa5d98e543632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2f29d93b50344d18632ee35a90b3013": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c44a7838338341a3a845680d2ab1341a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c84ab06afe1948a9be90109f20c8d3aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca6aefb7f2fe4143a7dd2cde1a40255b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdccc14b5a2a4e59b88c191f3f19e38e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4a7be23d5424284ba2b8623dc38a446": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e64b1ac4a7b848ceaa4c4725afc944bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e654c3267ae84924912e47b8a5d3f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38cd83e638134e69b4c1dcbdba286688",
       "IPY_MODEL_8603dc2bb7794c64b66e29c9cf1ea2d9",
       "IPY_MODEL_3f3730a17c9841e4b726e444f0e361a5"
      ],
      "layout": "IPY_MODEL_e4a7be23d5424284ba2b8623dc38a446"
     }
    },
    "eaafcb3b2cbc42d3bf81539f9a42ead9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef42b603953647af94ef83a0e992a1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f29d93b50344d18632ee35a90b3013",
      "placeholder": "",
      "style": "IPY_MODEL_747024b3473d465b85109294fd926238",
      "value": "pytorch_model.bin:100%"
     }
    },
    "f074a90818ab42a7885ee407cf5ffa7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d2af33b8e0c4198aef64a56b20ca1eb",
      "placeholder": "",
      "style": "IPY_MODEL_20e838e97d564e7583db5a606b43fb2c",
      "value": "modeling_florence2.py:100%"
     }
    },
    "f0b6122c13cc4eea97aa7dc6ab13a3c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f074a90818ab42a7885ee407cf5ffa7f",
       "IPY_MODEL_394a13b7f49f4d70b7ebd7ea6f5924ac",
       "IPY_MODEL_077a1fcc8a14437c96b9b61bea0e02b3"
      ],
      "layout": "IPY_MODEL_629fd09a98b546adb8ffc4a66a9664ea"
     }
    },
    "f4107cdf82f446ff88ac544487aedd4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4344dec7b914275b53db4d4362ba01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f80e27fc19864adc9eccaeb8fb947138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f88034dc172a47e0b980cad80c657bb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f884d62dbdd6491e95d690fc9020e491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa631ad069154a899fa46c02a0d3a8c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6f69234b4974985a30dc9a40e686eb5",
      "placeholder": "",
      "style": "IPY_MODEL_f4344dec7b914275b53db4d4362ba01a",
      "value": "2.44k/2.44k[00:00&lt;00:00,200kB/s]"
     }
    },
    "fc5fe0bea7e94e38ab66bbe43edc28b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdcc974c39bb4eef807565b213b24549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
